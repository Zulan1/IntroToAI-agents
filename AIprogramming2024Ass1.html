
<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<title>AI Assignment 1</title>

</head>

<body>
	<center>
	<h1>Introduction to Artificial Intelligence </h1>
	<h3>Programming Assignment 1</h3>
	</center>
<hr>
	<h2>Environment simulator and agents for the Multi-Agent Pickup and Delivery problem in a hostile environment</h2>
<p>
In this first exercise you are asked to implement an environment
simulator for a variant of the well known Multi-Agent Pickup and Delivery (MAPD) problem.
Then, you will implement some agents that live in the environment
and evaluate their performance.

</p><p>
In the MAPD problem, a team of robots needs to pick up and deliver a set of packages.
Each package has a pickup location, and a delivery location. The robots need to
visit all pickup locations to pick up the packages, and then all the delivery locations to deliver the packages.
This problem is repeatedly solved and implemented nowadays in automated warehouses, such as some
operated by Amazon. A standard simplification is representing locations by graph nodes, and possible robot trajecteories between them by edges.
In particular, in many implementations, as in this assignment, a 2D grid-shaped graph is assumed. Some of the grid edges may be blocked,
either permenently or temporarily, known in advance in this assignment Initial robot locations are knowm.
Packages to be delivered may appear at any time, with origin and delivery locations known in advance in this assignment.
All the above is given in the input in a format specified below.

The problem is to pick up and deliver all the packages as quickly as possible. This is equivalent to finding an
appropriate shortest path in a graph. However,
unlike standard shortest path problems in graphs,
which have easy known efficient solution methods (e.g. the Dijkstra algorithm), here the
problem is that there is more than 1 vertex to visit, and their order
is not given.

</p><h3>MAPD problem environment</h3>

<p>
The environment consists of an undirected graph with the general shape of a grid, i.e.
vertice at integer locations (i,j) ranging from (0,0) to (X,Y) inclusive, with X and Y specified in the input.
There are edges along the x and y axes between every pair of neighboring vertices in the x and y directions.
However, some of these edges, as specified in the input, are initially blocked.

<p>
A robot agent (pickup and delivery robot) at a vertex automatically picks up a package at that vertex if there is one.
A picked up package stays with the robot until the robot reaches the package's delivery location, upon which the packege is
automatically delivered. Some unblocked edges, specified in the input, are known to be fragile, and become permanently blocked after
an agent traverses them. Package initial locations and time of appearance are specified in the input, as well as target locations
and delivery deadline.
There is also another type of agent, that also travels the graph, but does not pick up or deliver any packages. 
Its only role is to block fragile edges by crossing them, and interfering. Both agents types 
can only do  <b>traverse</b> and <b>no-op</b> actions.
Each action takes 1 time unit. 
The action always succeeds if the edge to be traversed is unblocked and there is no other agent at the destination;
otherwise the action behaves the same as <b>no-op</b>.
The simulation ends when all packages have been delivered, or there is no path for any agent to pick up or deliver any more packages on time.
</p><p>
The simulator should keep track of time, the number of
actions done by each agent, and the total number packages successfully delivered by each agent.
For simplicity, we assume in this assignment that agents take turns, each move advancing the clock by 1, and do not move concurently.

</p><h3>Implementation part I: simulator + simple agents</h3>
 
<p>
Initially you will implement the environment simulator, and several simple
(non-AI) agents. The environment simulator should start up by reading
the problem instance specification from a file,
in a format of your choice. We suggest the following format,
using a simple ASCII file. For example (comments beginning
with a semicolon):

</p>
<pre>
#X 4                ; Maximum x coordinate
#Y 3                ; Maximum y coordinate
#P 4 0 0  D 0 3 50  ; Package at (4,0) from time 0, deliver to (0,3) on or before time 50
#P 0 3 5  D 4 0 50  ; Package at (0,3) from time 5, deliver to (4,0) on or before time 50

#B 3 0 4 0          ; Edge from (3,0) to (4,0) is always blocked
#B 2 2 2 3          ; Edge from (2,2) to (2,3) is always blocked
#F 0 0 0 1          ; Edge from (0,0) to (0,1) is fragile (can only be traversed once)
#A 0 0              ; Normal agent starts at (0,0)
#H 4 3              ; "Human" agent (see below)  starts at (4,3)
#I 1 1              ; Interfering agent (see below) starts at (1,1)
</pre>

<p>
As an initialization, the simulator should read the input file, and activate an agent program for each of the agents
stated in the file. 

</p><p>
After the above initialization, the simulator should run each agent program in turn, in the order they appear in the input file,
performing the actions retured by the agents, and update the world
accordingly. Additionally, the simulator should be capable of displaying the
state of the world after each step, with the appropriate 
state of the agents and their score. The score of an agent is the number of packages delivered on time by that agent.
A simple screen display in ASCII is sufficient (no bonuses
for fancy graphics - this is not the point in this course!).

</p><p>
Each agent program (a function) works as follows. 
The agent is called by the simulator, together with
a set of observations (can be a pointer to the state of the world as we have full observability in this assignment). 
The agent returns a move to be carried out in the 
current world state. The agent is allowed to keep an internal state
(for example, a computed optimal path, or anything else desired) if needed.

To make this more like standard MAPD, here the agents move quasi-concurrently, so need to check that they
do not both use the same edge (in opposite directions) at the same time. An agent may move to a location that contained another
agent if just before in the same time unit the other agent moved away from that location. A single move by all agents takes 1 time unit.
</p><p>
You should implement the following agents:

</p><ol>
<li> A <b>human</b> agent, i.e. print the state, read the next move from the user, and
return it to the simulator. This is used for debugging and evaluating the program.
</li><li> A <b> stupid greedy</b> agent, that works as follows: if the agent is not holding a package, it should
compute the shortest currently unblocked path to the next vertex with a package to be delivered,
and try to follow it. If it is holding a package, it should find the shortest path to a delivery location for the package,
and try to follow it. If holding more than 1 package, attempt to deliver the one with a shorter path to its delivery location.
If there is no such path, do <b>no-op</b>. Here and elsewhere, if needed, break ties by prefering lower-numbered
vertices in the x axis and then in the y axis. Stupidly ignores other agents.
</li><li> A <b> interfering</b> saboteur agent, that moves and tries to block fragile edges by traversing them. 
The saboteur works as follows: it computes the shortest path to a fragile edge, and moves in that direction.
If not possible, it does a no-op. The saboteur does not pick up packages.
Prefer the lowest-numbered vertices along the x axis and then the y axis in case of ties. Stupidly ignores other agents.
</li></ol>

<p>
At this stage, you should run the environment with up to <b>three</b> agents
participating in each run: one stupid greedy agent, one saboteur agent, and one
other agent (human or stupid greedy).
Your program should display and record the scores. In particular,
you should run the stupid greedy agent with various initial configurations.
Also, test your environment with several agents in the
same run, to see that it works correctly. You would be advised
to do a good job here w.r.t. program extensibility, modularity, etc.
much of this code may be used for some of the following
assignments as well. 

</p><p>
<b>Clarification and rationale:</b>
Note that this part of the assignment will not
really be checked, as it contains no AI, so details are not important.
The goal of this part of the assignment is constructing infrastructure 
for the rest of the assignment(s). E.g. the "human agent" is intended as
a debugging and demo aid, and also towards assignment 2, and the stupid greedy agent
contains code for shortest path that would be a component in a heuristic
in the 2nd part of this assignment.


</p><h3>Implementation part II: search agents</h3>

<p>
<b>Now</b>, after chapter 4, you will be implementing
intelligent agents (this is part 2 of the assignment)
that need to act in this environment. Although the real MAPD problem is intended for multiple robots,
and packages may appear at unknown times, in this assignment we only do a <b>single agent</b> search (but see bonus below if you wish) and
assume that the environment is deterministic and fully observable.
Each agent
should assume that it is acting alone, regardless of whether it is true.
You will be implementing a "search" agent as defined below.
All the algorithms will use an <b>admissible heuristic evaluation function</b> 
either the basic one  being an appropriately defined spanning tree heuristic discussed in the lecture, or a heuristic of your choice which dominates
the basic heuristic. 
The search algorithms you implement should 
search for a path that minimizes the time to deliver all packages in the grid, subject to each package being delivered on or before its deadline.

</p><ol>
<li> A greedy search agent,
 that picks the move with best immediate heuristic value to expand next.
</li><li> An agent using A* search, with the same heuristic. Assume a global constant of LIMIT
expansions (default 10000) beyond which we just return "fail", and the agent does just the "no-op"
action.
</li><li> An agent using real-time A* doing L (user determined constant,
L=10 by default) expansions before each move decision.
</li></ol>

<p>
The performance measure will be based on the "situated planning and search" idea of goal achievment time,
that is, recognizing that the search algorithm run also takes time!
Rather than using a real-time clock, we will simply have a per-expansion time
T, and if N expansions are run in the search
algorithm this means that N*T time has passed in real time.
The performance of an agent will thus be equal to S, when the path is actually executed in
"real time". For simplicity, we will start with T=0, that is,
assuming that search takes no time.

</p><p>
Note that if T is non-zero,
a path that looks optimal may actually
be bad because we have wasted a lot of time to find it,
when a simple quickly found path may be almost as good.
The number of expansions are: 1 per action for the greedy agent
(always 1 expansion),  and L for the "real-time A*".
We will run all algorithms with values of T being 0, 0.000001, and 0.01
and report the performance results.

</p><p>
Observe that for "situated" A* this is a very hard problem for an algorithm that considers the deadline,
as we do not know the number of
expansions before we do the search! Many search applications just assume that the number of
expansions is maximal and equal to LIMIT, or ignore the effect on the goal achievement time,
but determining how to do this in a reasonable
manner is an open research problem. (Do this to earn an MSc, or even a PhD.)

</p><p>
<b>Bonus version 1</b>: construct a search agent as above, but in addition
allow one saboteur agent also acting in the environment.
Your search agent needs to take this into account.
Observe that although this seems to be a multi-agent problem,
the fact that saboteur is perfectly predictable makes this in essence a single agent search problem.

<b>Bonus version 2</b>: construct a search agent as above, but in addition
allow one additional normal agent also acting in the environment. This is a move towards making this a
<b>multi</b> agent pickup and delivery, as in the actual warehouse application.
Your search agent needs to take this into account.
Observe that although this seems to be a multi-agent problem,
the fact that the other agent is perfectly predictable makes this in essence a single agent search problem.
Here the agents move truly in parallel.
Agents here are assumed to have
centralized control, i.e. a single algorithm computes a path for both of them.

</p><p>
<b>Addtional bonus - theoretical</b>: What is the computational complexity of the
MAPD Problem (single agent)? Can you prove that it is NP-hard? Or is it
in P? If the latter, can you design an algorithm that solves the problem in polynomial time?

</p><h2>Deliverables</h2>

<p>
The program and code sent to the grader, by e-mail or
otherwise as specified by the grader, a printout of the code and results.
A document stating the heuristic function you used and the rationale
for selecting this function.
Set up a time for frontal grading checking of the delivered assignment,
in which both members of each team must demonstrate at least <b>some</b>
familiarity with their program...

</p><p>

Due date for part 1 (recommended, not checked or enforced):  January 1, 2024.
</p><p>
For the complete assignment:  January 15, 2024. This assignment may be done in pairs.


</p></body></html>